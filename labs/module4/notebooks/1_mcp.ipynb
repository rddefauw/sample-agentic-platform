{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Agents: Model Context Protocol (MCP) Lab\n",
    "Welcome to the Model Context Protocol (MCP) lab! In this hands-on session, you'll learn about MCP - an open protocol released by Anthropic that standardizes how applications provide context to LLMs.\n",
    "\n",
    "## What is MCP?\n",
    "Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.\n",
    "\n",
    "The concept of MCP is simple. Create an open standard for how LLMs communicate with tools, resources, and prompts. As you may have noticed, nothing is standardized across generative AI. Different frameworks have different tool definitions, each API provider has a different API definition (even message definition), frameworks all do things differently. It ends up creating a lot of effort to make things all play together nicely. \n",
    "\n",
    "MCP aims to solve at least part of that puzzle. By creating an open specification for how people should define tools, prompts, and resources, we can start making pluggable and reusable agent components.\n",
    "\n",
    "## What We'll Build\n",
    "In this lab, we will:\n",
    "1. Create an MCP Server hosting our custom tools\n",
    "2. Set up an MCP Client which will consume our tool server\n",
    "3. Integrate with other open source MCP servers\n",
    "\n",
    "By the end of this lab, you'll understand how MCP creates a unified interface for LLMs to access external data and functionality, making your AI applications more modular, maintainable, and interoperable.\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an MCP Server\n",
    "MCP servers are simple using the python SDK. Define your tools and add type annotations. Then build and run the server. once started, FastMCP (part of the SDK) will automatically convert your tools into an MCP compatible server that can used by an agent. Servers can either be local (connected over STDIO) or remote (connected over HTTP SSE). They can also be written in different languages. For example, lots of servers are written in Typescript. The ones we'll write here are Python for consistency, but we'll also import 3P servers that are written in a variety of languages. \n",
    "\n",
    "The two MCP standard APIs we'll be playing with today are list-tools and call-tool. \n",
    "\n",
    "Here's a simple MCP server with two tools to call a weather API to get alerts and weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import requests\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "import logging\n",
    "\n",
    "class WeatherToolServer:\n",
    "    \"\"\"A simple MCP server providing weather-related tools.\"\"\"\n",
    "    \n",
    "    def __init__(self, name=\"weather\"):\n",
    "        self.mcp = FastMCP(name)\n",
    "        self.API_BASE = \"https://api.weather.gov\"\n",
    "        self._register_tools()\n",
    "    \n",
    "    def _make_request(self, url: str) -> Dict[str, Any]:\n",
    "        \"\"\"Make a request to the weather API.\"\"\"\n",
    "        headers = {\"User-Agent\": \"weather-app/1.0\", \"Accept\": \"application/geo+json\"}\n",
    "        try:\n",
    "            logging.debug(f\"Making request to {url}\")\n",
    "            response = requests.get(url, headers=headers, timeout=10.0)\n",
    "            logging.debug(f\"Response status: {response.status_code}\")\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in API request: {str(e)}\")\n",
    "            return {}\n",
    "    \n",
    "    def _register_tools(self):\n",
    "        \"\"\"Register all weather tools with the MCP server.\"\"\"\n",
    "        \n",
    "        @self.mcp.tool()\n",
    "        def get_alerts(state: str) -> str:\n",
    "            \"\"\"Get weather alerts for a US state.\n",
    "            \n",
    "            Args:\n",
    "                state: Two-letter US state code (e.g. CA, NY)\n",
    "            \"\"\"\n",
    "            data = self._make_request(f\"{self.API_BASE}/alerts/active/area/{state}\")\n",
    "            \n",
    "            if not data.get(\"features\"):\n",
    "                return \"No active alerts for this state.\"\n",
    "                \n",
    "            alerts = []\n",
    "            for feature in data[\"features\"]:\n",
    "                props = feature[\"properties\"]\n",
    "                alerts.append(f\"Event: {props.get('event')}\\nArea: {props.get('areaDesc')}\\nSeverity: {props.get('severity')}\")\n",
    "            \n",
    "            return \"\\n---\\n\".join(alerts)\n",
    "        \n",
    "        @self.mcp.tool()\n",
    "        def get_forecast(latitude: float, longitude: float) -> str:\n",
    "            \"\"\"Get weather forecast for a location.\n",
    "            \n",
    "            Args:\n",
    "                latitude: Latitude of the location\n",
    "                longitude: Longitude of the location\n",
    "            \"\"\"\n",
    "            # Get points data and extract forecast URL\n",
    "            points_data = self._make_request(f\"{self.API_BASE}/points/{latitude},{longitude}\")\n",
    "            if not points_data:\n",
    "                return \"Unable to fetch forecast data for this location.\"\n",
    "                \n",
    "            forecast_url = points_data.get(\"properties\", {}).get(\"forecast\", \"\")\n",
    "            if not forecast_url:\n",
    "                return \"Forecast URL not available.\"\n",
    "                \n",
    "            # Get the actual forecast\n",
    "            forecast_data = self._make_request(forecast_url)\n",
    "            if not forecast_data:\n",
    "                return \"Unable to fetch forecast.\"\n",
    "                \n",
    "            # Format just the essential information\n",
    "            result = []\n",
    "            for period in forecast_data.get(\"properties\", {}).get(\"periods\", [])[:3]:\n",
    "                result.append(f\"{period['name']}: {period['temperature']}Â°{period['temperatureUnit']}, {period['shortForecast']}\")\n",
    "                \n",
    "            return \"\\n\".join(result)\n",
    "    \n",
    "    def get_server(self):\n",
    "        \"\"\"Return the configured MCP server.\"\"\"\n",
    "        return self.mcp\n",
    "\n",
    "\n",
    "# Leave this commented out, but this is how you would run the server\n",
    "# app = WeatherToolServer().get_server()\n",
    "# if __name__ == \"__main__\":\n",
    "#     app.run(transport=\"stdio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the server\n",
    "You can run the server in a couple ways. In this notebook, we'll run it with nest_asyncio. You can also debug it using the mcp run dev command. This will open up an inspector on your local host and you can tinker around with the server. \n",
    "\n",
    "For unit/integ tests, we recommend you just call the server object directly and validate the code. \n",
    "\n",
    "```bash\n",
    "$ uv run mcp dev weather_server.py\n",
    "\n",
    "# Expected output of the command.\n",
    "Spawned stdio transport\n",
    "Connected MCP client to backing server transport\n",
    "Created web app transport\n",
    "Created web app transport\n",
    "Set up MCP proxy\n",
    "ðŸ” MCP Inspector is up and running at http://127.0.0.1:6274 ðŸš€\n",
    "```\n",
    "\n",
    "This will spin up the MCP Inspector locally on port 6274. Inspector is teh easiest way to debug your server locally at the moment. \n",
    "\n",
    "## How we'll test. \n",
    "In this next section we'll just call the server APIs programmatically using the FastMCP object created from WeatherToolServer().get_server()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets dump out the tool defintions from our MCP server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's best practice to import as MCPTool to avoid confusion with other tool definitions from different places\n",
    "# Including other frameworks or even our own. \n",
    "from mcp import Tool as MCPTool\n",
    "\n",
    "from typing import List\n",
    "\n",
    "mcp_server: FastMCP = WeatherToolServer().get_server()\n",
    "\n",
    "# Define an async function to get tools\n",
    "async def get_tools():\n",
    "    tools: List[MCPTool] = await mcp_server.list_tools()\n",
    "    for tool in tools:\n",
    "        print(tool.model_dump_json(indent=2))\n",
    "\n",
    "# Run the async function\n",
    "asyncio.run(get_tools())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, it looks like our tool server is returning our function definitions correctly! Now lets try to invoke the tool and test out the server using the mcp object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's best practice to import as MCPTool to avoid confusion with other tool definitions from different places\n",
    "# Including other frameworks or even our own. \n",
    "from mcp.types import TextContent as MCPTextContent, ImageContent as MCPImageContent, EmbeddedResource as MCPEmbeddedResource\n",
    "from typing import List, Any\n",
    "\n",
    "mcp_server: FastMCP = WeatherToolServer().get_server()\n",
    "\n",
    "# Define an async function to get tools\n",
    "async def call_tool(name: str, arguments: Dict[str, Any]) -> None:\n",
    "    results: List[MCPTextContent | MCPImageContent | MCPEmbeddedResource] = await mcp_server.call_tool(name, arguments)\n",
    "    for result in results:\n",
    "        print(result.model_dump_json(indent=2))\n",
    "\n",
    "# Run the async function\n",
    "asyncio.run(call_tool(\"get_alerts\", {\"state\": \"CA\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an MCP Client\n",
    "Nice! We've now tested our server code and can see the MCP protocol in action. There's nothing too complicated about it. It's just a common interface (abstraction) that the protocol dictates. \n",
    "\n",
    "## Connecting a Client to an MCP Server\n",
    "MCP Servers can connect in two ways, either over STDIO and HTTP SSE. With STDIO running your own MCP server, you specify a server config pointing to the absolute file path for the server and a command to run. MCP locally will spin up that server as a subprocess and maintain a connection with it. This is the path we'll take. Like shown above, the MCP spec is changing to make remote servers easier to use. As of 4/5/2025, we recommend running the servers locally until the spec updates propagate into the SDKs. Without that change, you end up doing unnatural things and writing shims to get it to function in a production system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets get the absolute path to our weather server and setup our server params using MCPs StdioServerParameters class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "# We need the full path to the weather server\n",
    "import os\n",
    "# Get the absolute path to the weather server\n",
    "current_dir = os.getcwd()\n",
    "weather_server_path = os.path.join(current_dir, 'mcp_servers', 'weather_server', 'weather_server.py')\n",
    "\n",
    "server_params = StdioServerParameters(  \n",
    "    command = 'uv',\n",
    "    args=['run', 'mcp', 'run', weather_server_path]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets test out the connection using a test function. We'll use the mcp SDK to directly connect to the server without any agent framework.\n",
    "\n",
    "stdio_client and ClientSession are async so we need to wrap the call in asyncio so that it runs in a jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp import ClientSession\n",
    "from mcp.client.stdio import stdio_client\n",
    "from mcp.types import ListToolsResult\n",
    "\n",
    "async def test_mcp_client():\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            print('initializing session')\n",
    "            await session.initialize()\n",
    "            tools: ListToolsResult = await session.list_tools()\n",
    "\n",
    "            # Print out the tools from our client. \n",
    "            for t in tools.tools:\n",
    "                print(t.name)\n",
    "                print(t.description)\n",
    "                print(t.inputSchema)\n",
    "                print('-'*100)\n",
    "\n",
    "\n",
    "asyncio.run(test_mcp_client())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect our MCP Servers to an Agent\n",
    "We could re-use the agent we created from scratch in module 3, however we have lots of useful frameworks that now work interchangably with the rest of our code. I don't see the point in reinventing the wheel if the framework does what we need out of the box. Lets use the PydanticAI agent we created in the previous workshop and leverage it's MCP features. \n",
    "\n",
    "PydanticAI comes with two ways to connect to MCP servers:\n",
    "* MCPServerHTTP which connects to an MCP server using the HTTP SSE transport\n",
    "* MCPServerStdio which runs the server as a subprocess and connects to it using the stdio transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we wrap our own MCP server in a MCPServerStdio object\n",
    "from pydantic_ai.mcp import MCPServerStdio as PyAIMCPServerStdio\n",
    "\n",
    "custom_weather_mcp_server = PyAIMCPServerStdio(  \n",
    "    command = 'uv',\n",
    "    args=['run', 'mcp', 'run', weather_server_path]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent as PyAIAgent\n",
    "\n",
    "# Add the MCP Server params to the agent.\n",
    "weather_agent: PyAIAgent = PyAIAgent(\n",
    "    'bedrock:us.anthropic.claude-3-5-haiku-20241022-v1:0',\n",
    "    system_prompt='You are a helpful assistant.',\n",
    "    mcp_servers=[custom_weather_mcp_server]\n",
    ")\n",
    "\n",
    "# We can reuse this to run multiple agents with different servers.\n",
    "async def run_pydantic_ai_mcp_client(user_msg: str,agent: PyAIAgent):\n",
    "    async with agent.run_mcp_servers():\n",
    "        result = await agent.run(user_msg)\n",
    "    print(result.data)\n",
    "\n",
    "# Run the agent with a user message.\n",
    "user_msg = 'Can you show me any weather alerts for California?'\n",
    "asyncio.run(run_pydantic_ai_mcp_client(user_msg, weather_agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this lab we successfully created an MCP server, connected it to an MCP client (using PydanticAI), and were able to augment our LLM with this custom server.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
